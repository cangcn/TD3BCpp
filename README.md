# Implenmentation of TD3BC++

This is the code for the TD3BC++ algorithm proposed in arxiv paper **Robust Offline Reinforcement Learning from Contaminated Demonstrations**. 

We show that policy constraint offline RL methods often suffer learning from the contaminated dataset, which is the combination of both expert and non-expert demonstrations. To recover the performance, we propose to use gradient penalty on the learning Q-function, and then relax the closeness constraint toward non-expert dataset decisions. 



For the algorithmic details, please read the white paper https://arxiv.org/pdf/2210.10469.pdf

For the conda environment, please see the 
